<!DOCTYPE html>
<html lang="en">
  <head>
    
      <title>HunterAI #3: Top-down Shooter AI :: Adam Jordan&#39;s Blog — Things I am interested in</title>
    
    <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="description" content="About HunterAI
This is a series of my project devlog to create a certain complex AI. In each devlog, I will write about my progress in developing and upgrading the complexity of the AI program from the previous version.
 Today&amp;rsquo;s Goal In this post, I will try to create a reflex agent with internal state in an imperfect information environment. The agent is a top-down shooter with a limited vision range, therefore it needs to store information about the map it already visited."/>
<meta name="keywords" content=""/>
<meta name="robots" content="noodp"/>
<link rel="canonical" href="https://blog.adamjordan.id/posts/005-hunterai-topdown-shooter-ai/" />





<link rel="stylesheet" href="https://blog.adamjordan.id/assets/style.css">


<link rel="stylesheet" href="https://blog.adamjordan.id/style.css">


<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://blog.adamjordan.id/img/apple-touch-icon-144-precomposed.png">
<link rel="shortcut icon" href="https://blog.adamjordan.id/img/favicon.png">


<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="HunterAI #3: Top-down Shooter AI"/>
<meta name="twitter:description" content="In this post, I will try to create a **reflex agent with internal state** in an imperfect information environment. The agent is a top-down shooter with a limited vision range, therefore it needs to store information about the map it already visited. Furthermore, it needs to make a rational decision to find the enemies and make necessary actions shoot them. "/>



<meta property="og:title" content="HunterAI #3: Top-down Shooter AI" />
<meta property="og:description" content="In this post, I will try to create a **reflex agent with internal state** in an imperfect information environment. The agent is a top-down shooter with a limited vision range, therefore it needs to store information about the map it already visited. Furthermore, it needs to make a rational decision to find the enemies and make necessary actions shoot them. " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://blog.adamjordan.id/posts/005-hunterai-topdown-shooter-ai/" />
<meta property="article:published_time" content="2020-01-28T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-01-28T00:00:00+00:00" /><meta property="og:site_name" content="Adam Jordan&#39;s Blog" />






  </head>
  <body class="">
    <div class="container">
      <header class="header">
  <span class="header__inner">
    <a href="/" class="logo" style="text-decoration: none;">
  
    <span class="logo__mark"><svg xmlns="http://www.w3.org/2000/svg" class="greater-icon" viewBox="0 0 44 44">
  <path fill="none" d="M15 8l14.729 14.382L15 35.367"/>
</svg>
</span>
    <span class="logo__text">Adam Jordan&#39;s Blog</span>
    <span class="logo__cursor"></span>
  
</a>

    <span class="header__right">
      
        <nav class="menu">
  <ul class="menu__inner menu__inner--desktop">
    
      
        
          <li><a href="/security">Security</a></li>
        
      
        
          <li><a href="/archive">Archive</a></li>
        
      
        
          <li><a href="/about">About</a></li>
        
      
      
    
  </ul>

  <ul class="menu__inner menu__inner--mobile">
    
      
        <li><a href="/security">Security</a></li>
      
    
      
        <li><a href="/archive">Archive</a></li>
      
    
      
        <li><a href="/about">About</a></li>
      
    
  </ul>
</nav>

        <span class="menu-trigger">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M0 0h24v24H0z" fill="none"/>
            <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
          </svg>
        </span>
      
      <span class="theme-toggle">
        <svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
</svg>

      </span>
    </span>
  </span>
</header>


      <div class="content">
        
  <div class="post">
    <h2 class="post-title"><a href="https://blog.adamjordan.id/posts/005-hunterai-topdown-shooter-ai/">HunterAI #3: Top-down Shooter AI</a></h2>
    <div class="post-meta">
      
        <span class="post-date">
            28-01-2020
        </span>
      
      <span class="post-author">— Written by Adam Jordan</span>
      
        <span class="post-read-time">— 12 min read</span>
      
    </div>

    
      <span class="post-tags">
        
          #<a href="https://blog.adamjordan.id/tags/ai/">ai</a>&nbsp;
        
          #<a href="https://blog.adamjordan.id/tags/devlog/">devlog</a>&nbsp;
        
          #<a href="https://blog.adamjordan.id/tags/hunter-ai/">hunter-ai</a>&nbsp;
        
          #<a href="https://blog.adamjordan.id/tags/unity/">unity</a>&nbsp;
        
      </span>
    

    

    <div class="post-content">
      

<blockquote>
<p><strong>About HunterAI</strong></p>

<p>This is a series of my project devlog to create <em>a certain complex</em> AI.
In each devlog, I will write about my progress in developing and upgrading the complexity of the AI
program from the previous version.</p>
</blockquote>

<h2 id="today-s-goal">Today&rsquo;s Goal</h2>

<p>In this post, I will try to create a <strong>reflex agent with internal state</strong> in an imperfect information environment.
The agent is a top-down shooter with a limited vision range, therefore it needs to store information about the map it already visited.
Furthermore, it needs to make a rational decision to find enemies and take necessary actions to shoot them.</p>

<p><em>For future reference, today&rsquo;s version will be referenced as <strong>Caleb</strong>.</em></p>

<p><img src="/post_assets/005/preview.png" alt="Visualization" /></p>

<h2 id="the-scenario">The Scenario</h2>

<p>We are going to expand from the <a href="https://blog.adamjordan.id/posts/002-hunterai-connecting-agent-with-unity/">previous scenario</a>.
In today&rsquo;s scenario, we are going to put our hunter in a grid of <code>M x N</code>.</p>

<ul>
<li>There will be some monsters placed at random coordinates.</li>
<li>Hunter&rsquo;s vision range is limited. Thus making hunter to not have perfect information.</li>
<li>Projectile range is limited. Thus, hunter needs to position itself accordingly to shoot monsters.</li>
<li>In a moment, the action that hunter can take is: $MoveForward$, $RotateLeft$, $RotateRight$, or $Shoot$.</li>
</ul>

<h2 id="demo">Demo</h2>


<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/XRnqPfFGsps" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>


<h2 id="finding-shortest-path-with-bfs">Finding Shortest Path with BFS</h2>

<p>In this scenario, we are going to face a problem where we need to find the shortest path to multiple cells.
For example, there are multiple monsters in the grid, and hunter needs to approach the nearest monster.</p>

<p>To solve this problem, we can use Breadth-first-Search (BFS);
with Hunter&rsquo;s coordinate as starting point and monsters coordinates as goals.
With BFS, since we are going to do level order traversal, the first goal that we reach is the nearest goal.
We can then follow the path formed, which is the shortest path to the nearest goal.</p>


  <figure class="center" >
    <img src="/post_assets/005/drawing-bfs.png"  alt="BFS to find nearest target"   style="max-height: 300px;"  />
    
      <figcaption class="center" >BFS to find nearest target</figcaption>
    
  </figure>



<pre><code class="language-python"># caleb/algorithm/bfs.py

def neighbors(current, grid):
    size_x = len(grid[0])
    size_y = len(grid)

    res = []
    if current[0] - 1 &gt;= 0:
        res.append((current[0] - 1, current[1]))
    if current[0] + 1 &lt; size_x:
        res.append((current[0] + 1, current[1]))
    if current[1] - 1 &gt;= 0:
        res.append((current[0], current[1] - 1))
    if current[1] + 1 &lt; size_y:
        res.append((current[0], current[1] + 1))
    return res


def bfs(start, goals, grid):
    &quot;&quot;&quot;
    Using BFS to get path to nearest goal.
    &quot;&quot;&quot;
    size_x = len(grid[0])
    size_y = len(grid)

    visited = [[False for _ in range(size_x)] for _ in range(size_y)]
    parent = [[None for _ in range(size_x)] for _ in range(size_y)]
    queue = [start]
    visited[start[1]][start[0]] = True

    while queue:
        current = queue.pop(0)
        if current in goals:
            path = []
            while parent[current[1]][current[0]]:
                path.append(current)
                current = parent[current[1]][current[0]]
            return path[::-1]
        for neighbor in neighbors(current, grid):
            if not visited[neighbor[1]][neighbor[0]]:
                queue.append(neighbor)
                parent[neighbor[1]][neighbor[0]] = current
                visited[neighbor[1]][neighbor[0]] = True

    raise ValueError('No Path Found')
</code></pre>

<p>Let&rsquo;s create a test script to check the correctness of our implementation.</p>

<pre><code class="language-python"># caleb/test.py

def test_bfs():
    grid_str = [
        '-M------',
        '------M-',
        '--M-----',
        '--------',
        '--------',
        '--------',
        '----H---',
        '--------',
    ]

    print('\nTesting: BFS to nearest monster\n')

    grid, hunter, monsters = parse_grid(grid_str)
    debug_grid(grid)

    while True:
        if hunter in monsters:
            break
        path = bfs.bfs(hunter, monsters, grid)
        next_hunter = path[0]
        set_content(grid, hunter, GridContent.EMPTY)
        set_content(grid, next_hunter, GridContent.HUNTER)
        hunter = next_hunter
        debug_grid(grid, refresh=False)


if __name__ == '__main__':
    test_bfs()
</code></pre>

<p>By running the test script, we can see that the hunter is going toward the monster on the left bottom, which is the nearest monster.</p>

<iframe src="https://player.vimeo.com/video/387264527?autoplay=1&loop=1&muted=1" style="border:0; width: 100%; height: 300px"></iframe>


<h2 id="the-agent-implementation-in-python">The Agent Implementation in Python</h2>

<p>I will reuse the concepts explained from previous posts:</p>

<ul>
<li><a href="https://blog.adamjordan.id/posts/001-hunterai-creating-simple-intelligent-agent/">Creating simple Intelligent Agent &amp; the fundamental concepts</a></li>
<li><a href="https://blog.adamjordan.id/posts/002-hunterai-connecting-agent-with-unity/">Connecting agent program with Unity frontend visualization</a></li>
</ul>

<h3 id="generalized-remote-architecture-and-remote-environment-framework">Generalized Remote Architecture and Remote Environment Framework</h3>

<p>Based on the idea in <a href="https://blog.adamjordan.id/posts/002-hunterai-connecting-agent-with-unity/">previous version</a>,
let&rsquo;s make it more generalized for remote architecture and remote environment.
So in the future we might be able to reuse the general piece of code.</p>

<p>For remote architecture, there are two functions that we must implement in an <code>Architecture</code> class.</p>

<ul>
<li>In <code>perceive</code> function, we just return a Percept instance containing the environment state.</li>

<li><p>In <code>act</code> function, we just pass the action to remote environment through <code>set_remote_action</code>.</p>

<pre><code class="language-python"># caleb/architecture.py

from alexander.concepts import Percept, Architecture


class GeneralRemoteArchitecture(Architecture):
    def perceive(self, environment):
        return Percept(environment.state)

    def act(self, environment, action):
        environment.set_remote_action(action)
</code></pre></li>
</ul>

<p>For remote environment:</p>

<ul>
<li>We store a state in a Key-Value data structure.</li>

<li><p>We provide a function to update this state data: <code>update_state</code>.</p>

<pre><code class="language-python"># caleb/environment.py

from barton.concepts import RemoteEnvironment


class GeneralRemoteEnvironment(RemoteEnvironment):
    def __init__(self):
        super().__init__()
        self.state = {}

    def update_state(self, state):
        self.state = state
</code></pre></li>
</ul>

<h3 id="implementing-the-hunter-agent-program">Implementing the Hunter Agent Program</h3>

<p>Next, we are going to write the Hunter agent program.
First, let&rsquo;s define the actions that the hunter agent can possibly do.
Also define the possible content of a cell in the grid.</p>

<pre><code class="language-python"># caleb/program.py (partial)

class Actions(Enum):
    MOVE_FORWARD = Action('move_forward')
    SHOOT = Action('shoot')
    ROTATE_LEFT = Action('rotate_left')
    ROTATE_RIGHT = Action('rotate_right')

class GridContent(Enum):
    UNKNOWN = -1
    EMPTY = 0
    MONSTER = 1
    HUNTER = 2
</code></pre>

<p>Our agent is a <strong>reflex agent with internal state</strong>.
The state information is initiated at <code>__init__()</code>.
The <code>process()</code>, which implements the agent function, will perform three tasks when invoked:</p>

<ul>
<li>Update the agent&rsquo;s state to reflect new percept;</li>
<li>Choose the best action;</li>
<li>Update the agent&rsquo;s state according to action.</li>
</ul>

<p>The code:</p>

<pre><code class="language-python"># caleb/program.py (partial)

class HunterProgram(Program):
    def __init__(self):
        pass # todo: initiate default state here

    def process(self, percept):
        self.update_state_with_percept(percept)
        action = self.choose_action()
        self.update_state_with_action(action)
        return action

    def update_state_with_percept(self, percept):
        pass # todo

    def choose_action(self):
        return None # todo

    def update_state_with_action(self, action):
        pass # todo
</code></pre>

<p>Then, we are going to write the main file.
In main, we define our <code>init_function</code> that will instantiate the hunter environment and agent.
Then we pass the it to Remote module (Read <a href="https://blog.adamjordan.id/posts/002-hunterai-connecting-agent-with-unity/">previous post</a>), and run the python remote server.</p>

<pre><code class="language-python">from alexander.concepts import Agent
from barton.remote import Remote
from .architecture import GeneralRemoteArchitecture
from .environment import GeneralRemoteEnvironment
from .program import HunterProgram


def init_function():
    environment = GeneralRemoteEnvironment()
    program = HunterProgram()
    architecture = GeneralRemoteArchitecture()
    agent = Agent(program, architecture)
    return environment, [agent]


if __name__ == '__main__':
    remote = Remote(init_function)
    remote.app().run(debug=True)
</code></pre>

<p>We can now run the hunter agent by running <code>main.py</code>.</p>

<pre><code class="language-bash">$ python3 -m caleb.main
 * Serving Flask app &quot;barton.remote&quot; (lazy loading)
 * Environment: production
 * Debug mode: on
 * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)
</code></pre>

<h3 id="the-cli-world-environment">The CLI World Environment</h3>

<p>Before building the world environment with Unity, we can first build an environment with CLI.</p>

<p>The <code>cli_world.py</code> contains an implementation of hunter world environment.
When running, it will communicate with the Hunter agent via HTTP connection and update itself in an eternal loop.
In each loop step, it will update itself, send the environment state to agent, and actuate the action received from agent to the environment.</p>

<pre><code class="language-python"># caleb/test/cli_world.py

class CliWorld:

    def __init__(self, grid_str, hunter_face):
        self.grid, self.hunter, self.monsters = parse_grid(grid_str)
        self.hunter_face = hunter_face

    def run(self):
        self.debug(sleep=1)
        self.init()
        while True:
            self.update()
            state = self.get_state()
            step_response = self.step(state)
            self.actuate(step_response['action'])
            self.debug(refresh=False, sleep=1)

    def init(self):
        requests.put('http://localhost:5000/init')

    def step(self, state):
        r = requests.put('http://localhost:5000/step', data=json.dumps(state))
        return r.json()

    ...


if __name__ == '__main__':
    grid_str = [
        '-M-------',
        '------M--',
        '--M------',
        '---------',
        '---------',
        '---------',
        '----H----',
        '---------',
        '---------',
    ]

    print('\nTesting: Hunter Agent\n')
    world = CliWorld(grid_str, hunter_face=0)
    world.run()
</code></pre>

<p>The State passed from this CLI World is as follows:</p>

<pre><code class="language-python">state = {
    'Vision': visionContent,
    'MonsterCount': len(self.monsters),
    'MapSize': {'x': map_size_x, 'y': map_size_y},
    'HunterPosition': self.hunter,
    'HunterRotation': self.hunter_face,
    'HunterProjectileDistance': 3
}
</code></pre>

<p>We can run the script and this CLI World will connect to our Hunter Agent program through HTTP connection.
However, there is no functionality as of now.</p>

<pre><code class="language-bash">$ python3 -m caleb.test.cli_world

Testing: Hunter Agent

  - M - - - - - - -
  - - - - - - M - -
  - - M - - - - - -
  - - - - - - - - -
  - - - - - - - - -
  - - - - - - - - -
  - - - - H - - - -
  - - - - - - - - -
  - - - - - - - - -
</code></pre>

<h2 id="implementing-the-agent-logic">Implementing the Agent Logic</h2>

<h3 id="scanning-grid-with-limited-vision">Scanning Grid with Limited Vision</h3>

<p>We are going to implement the algorithm of how our Hunter Agent can explore the grid.
Because our agent has limited vision, it does not have perfect information about the contents of every cells.
Thus, it need to store the content of the cells already seen.
We store it in <code>self.grid</code> variable.</p>

<p>In <code>update_state_with_percept</code>, we update the internal state with the percept received from environment.
We also update the <code>grid</code> variable with the <code>Vision</code> percept.</p>

<pre><code class="language-python">def update_state_with_percept(self, percept):
    if not self.initiated:
        self.grid_size = percept.state['MapSize']
        self.grid = [[GridContent.UNKNOWN for _ in range(self.grid_size['x'])] for _ in range(self.grid_size['y'])]
        self.initiated = True

    self.hunter_position = percept.state['HunterPosition']
    self.hunter_rotation = percept.state['HunterRotation']
    self.monster_count = percept.state['MonsterCount']
    self.hunter_projectile_range = percept.state['HunterProjectileDistance']
    for vision in percept.state['Vision']:
        x, y = vision['Position']
        self.grid[y][x] = GridContent(vision['Content'])
</code></pre>

<p>Then, in <code>choose_action</code>, we will return an action to move towards the nearest unknown cell.
Using the BFS algorithm we discussed earlier, we can know the shortest path to the nearest unknown cell.
Then, the hunter is heading to the first step in the shortest path, while considering rotation action if necessary.</p>

<pre><code class="language-python">def get_unknown_cells(self):
    unknown_cells = []
    for y, row in enumerate(self.grid):
        for x, col in enumerate(row):
            if col == GridContent.UNKNOWN:
                unknown_cells.append((x, y))
    return unknown_cells

def action_move_towards(self, cells):
    path_to_target = bfs.bfs(self.hunter_position, cells, self.grid)
    if path_to_target:
        next_cell = path_to_target[0]
        rotate_action = self.calc_rotate_action(next_cell) # check if rotation is necessary
        return rotate_action or Actions.MOVE_FORWARD.value

def choose_action(self):
    if self.monster_count &gt; 0:
        unknown_cells = self.get_unknown_cells()
        return self.action_move_towards(unknown_cells)
</code></pre>

<p>As of now, our Hunter Agent can already do basic grid scanning function.
With this function, the agent can gain more information inside the imperfect information environment.</p>

<iframe src="https://player.vimeo.com/video/387417991?autoplay=1&loop=1&muted=1" style="border:0; width: 100%; height: 300px"></iframe>


<h3 id="shooting-monsters">Shooting Monsters</h3>

<p>Now we are going to implement the functionality for our Hunter agent to shoot monsters.</p>

<p>The idea is as follows:</p>

<ul>
<li>List the coordinates of monsters already sighted.</li>
<li>If no monsters are sighted yet, move towards the nearest unknown cell.</li>
<li>Else, going to shoot the nearest monster:

<ul>
<li>Calculate the possible shooting position cells.
The shooting position is a coordinate in which the Hunter can shoot a monster in a direction.</li>
<li>If hunter already in shooting position, shoot the target. Do rotation if necessary.</li>
<li>If hunter is not yet in shooting position, use BFS to move towards the nearest shooting position.</li>
</ul></li>
</ul>

<p>The related code:</p>

<pre><code class="language-python"># caleb/program.py

def get_monster_cells(self):
    monsters_sighted = []
    for y, row in enumerate(self.grid):
        for x, col in enumerate(row):
            if col == GridContent.MONSTER:
                monsters_sighted.append((x, y))
    return monsters_sighted

def get_shooting_position_cells(self, monsters_sighted):
    target_cells = []
    target_cells_monster = {}
    for x, y in monsters_sighted:
        for i in range(1, self.hunter_projectile_range + 1):
            target_cells_curr = [(x + i, y), (x - i, y), (x, y + i), (x, y - i)]
            for target_cell in target_cells_curr:
                target_cells.append(target_cell)
                key = '%d,%d' % (target_cell[0], target_cell[1])
                target_cells_monster[key] = (x, y)
    return target_cells, target_cells_monster

def action_shoot_monster(self, target_cells_monster):
    key = '%d,%d' % (self.hunter_position[0], self.hunter_position[1])
    monster_cell = target_cells_monster[key]
    rotate_action = self.calc_rotate_action(monster_cell)
    return rotate_action or Actions.SHOOT.value

def choose_action(self):
    if self.monster_count &gt; 0:
        unknown_cells = self.get_unknown_cells()
        monsters_sighted = self.get_monster_cells()

        if len(monsters_sighted) == 0:
            return self.action_move_towards(unknown_cells)
        else:
            target_cells, target_cells_monster = self.get_shooting_position_cells(monsters_sighted)
            if self.hunter_position in target_cells:
                return self.action_shoot_monster(target_cells_monster)
            else:
                return self.action_move_towards(target_cells)
</code></pre>

<p>As of now, our agent is already fully working.
If we connect our agent with the previous <code>cli_world</code> environment, we can see that our agent is working as expected.</p>

<iframe src="https://player.vimeo.com/video/387427033?autoplay=1&loop=1&muted=1" style="border:0; width: 100%; height: 300px"></iframe>


<h2 id="the-unity-world-environment">The Unity World Environment</h2>

<p>Now that we already have a fully working agent in CLI environment,
let&rsquo;s make a 3D World environment visualized using Unity.
Please take a loot at &ldquo;<a href="https://blog.adamjordan.id/posts/002-hunterai-connecting-agent-with-unity/">Connecting agent program with Unity frontend visualization</a>&rdquo; to understand the mechanic to connect Unity visualization with our python agent program.</p>

<p><img src="/post_assets/005/unity.png" alt="The Unity Editor" /></p>

<p>As shown in the image above, I already made a Unity scene containing a grid of <code>M x N</code> cells.
The next thing interesting to discuss is the <code>simulation.cs</code> which contains the implementation of our simulation program logic.</p>

<ul>
<li><p>In <code>Initiate()</code>, we are going to initiate the connection with our agent program via <code>HunterSDK.Initiate()</code>.
Then, we will invoke <code>Step()</code> to be run every <code>SdkStepInterval</code> seconds (default: 0.1).</p></li>

<li><p>In <code>Step()</code>:</p>

<ul>
<li>Get state from Unity environment,</li>
<li>Send the state via <code>HunterSDK.Step()</code></li>
<li>Receive the action from the agent response, then actuate the action to Unity environment.</li>
</ul></li>
</ul>

<p>The code:</p>

<pre><code class="language-csharp">// simulator.cs

public class Simulator : MonoBehaviour
{
    public void Initiate()
    {
        ...
        if (SdkAiEnabled)
        {
            hunterSDK = new HunterSDK&lt;State, StepResponse&gt;(this, SdkHost);
            hunterSDK.Initiate();
            InvokeRepeating(&quot;Step&quot;, 2.0f, SdkStepInterval);
        }
        ...
    }

    void Step()
    {
        if (SdkAiEnabled)
        {
            TheHunter.ShowThinking(true);
            State state = GetState();
            hunterSDK.Step(state, (stepResponse) =&gt;
            {
                AgentAction action = stepResponse.action;
                ActuateAction(action);
                Helper.RunLater(this, () =&gt; TheHunter.ShowThinking(false), 0.1f);
            });
        }
    }

    public State GetState()
    {
        List&lt;GridWithContent&gt; vision = getVision();

        State state = new State();
        state.Vision = vision;
        state.MonsterCount = monsterObjs.Count;
        state.MapSize = TheGridManager.mapSize;
        state.HunterPosition = TheHunter.targetPosition;
        state.HunterRotation = Mathf.RoundToInt(TheHunter.targetRotation.eulerAngles.y);
        state.HunterProjectileDistance = HunterProjectileDistance;

        return state;
    }

    ...
}
</code></pre>

<p>I also created a simulation option panel that allows user to configure the simulation option.
For example, user can configure the grid size, the simulation step speed, or the hunter vision range.
This allows us to experiment further, such as knowing the optimal vision range (in case having long vision range costs something else).</p>


  <figure class="center" >
    <img src="/post_assets/005/option-panel.png"  alt="Hello Friend"   style="max-height: 400px;"  />
    
      <figcaption class="center" >Simulation Option Panel</figcaption>
    
  </figure>



<h3 id="the-challenges-with-unity-different-position-indexing">The Challenges with Unity: Different Position Indexing</h3>

<p>In Unity 3D, there are three axis in coordinates, i.e. <code>x</code>, <code>y</code>, <code>z</code>, which consecutively represents horizontal position, vertical position, and depth position.
Because we are interested in 2D grid, we can ignore <code>y</code> coordinate, thus focusing in <code>x</code> for horizontal axis in grid, and <code>y</code> for vertical axis in grid.</p>

<p>But there is another problem related in axis positional value.
In our python agent program, the grid is represented vertically in <em>X</em> axis from index <code>0</code> to <code>M</code>, and horizontally in <em>Y</em> axis from index <code>0</code> to <code>N</code>.
Meanwhile, in Unity, the position grid is represented vertically in <em>X</em> axis from index <code>-M/2</code> to <code>M/2</code>, and horizontally in <em>Y</em> axis from index <code>N/2</code> to <code>-N/2</code>.
This inconsistency proves to become a problematic hassle during implementation, making implementation prone to indexing errors.</p>


  <figure class="center" >
    <img src="/post_assets/005/drawing-indexing.png"   style="max-height: 300px;"  />
    
      <figcaption class="center" >Different indexing in Unity and our python program</figcaption>
    
  </figure>



<p>One way to solve this problem is by adding a position translation in python side:</p>

<pre><code class="language-python">def translate_pos(self, x, y):
    return self.grid_size['x'] // 2 + x, self.grid_size['y'] // 2 + y
</code></pre>

<h2 id="demo-conclusion">Demo &amp; Conclusion</h2>


<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/XRnqPfFGsps" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>


<p>Today, we learned how to create a <strong>reflex agent with internal state</strong> in an imperfect information environment.
Specifically, we created a top-down shooter AI with limited vision range to its surrounding.
Using common pathfinding algorithm (in this case, BFS), our AI agent is able to determine an efficient way to discover monsters and position itself in the nearest shooting position.</p>

<p>Combined with the configurability of our visualization, I believe this is a good learning material in learning how to implement and playing around basic AI.</p>

<h2 id="source-code">Source code</h2>

<p><a href="https://github.com/adamyordan/hunterAI/tree/master/caleb">https://github.com/adamyordan/hunterAI/tree/master/caleb</a></p>

<h2 id="reference">Reference</h2>

<ul>
<li><a href="https://people.eecs.berkeley.edu/~russell/aima1e/chapter02.pdf">https://people.eecs.berkeley.edu/~russell/aima1e/chapter02.pdf</a>
(Reference when implementing reflex agent function)</li>
</ul>

    </div>
    
      
        <div class="pagination">
          <div class="pagination__title">
            <span class="pagination__title-h">Read other posts</span>
            <hr />
          </div>
          <div class="pagination__buttons">
            
            
              <span class="button next">
                <a href="https://blog.adamjordan.id/posts/004-sectips-jan2020/">
                  <span class="button__text">SecTips #Jan20</span>
                  <span class="button__icon">→</span>
                </a>
              </span>
            
          </div>
        </div>
      
    
    

    
      
        
    <br><br>
    <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "adam-blog" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


      
    
    
    </div>

      </div>

      
        <footer class="footer">
  <div class="footer__inner">
    
      <a href="/" class="logo" style="text-decoration: none;">
  
    <span class="logo__mark"><svg xmlns="http://www.w3.org/2000/svg" class="greater-icon" viewBox="0 0 44 44">
  <path fill="none" d="M15 8l14.729 14.382L15 35.367"/>
</svg>
</span>
    <span class="logo__text">Adam Jordan&#39;s Blog</span>
    <span class="logo__cursor"></span>
  
</a>

      <div class="copyright">
        <span>© 2020 Powered by <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a></span>
        <span>Theme created by <a href="https://twitter.com/panr" target="_blank" rel="noopener">panr</a></span>
      </div>
    
  </div>
</footer>

<script src="https://blog.adamjordan.id/assets/main.js"></script>
<script src="https://blog.adamjordan.id/assets/prism.js"></script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        displayMath: [['$$','$$'], ['\[','\]']],
        processEscapes: true,
        processEnvironments: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
        TeX: { equationNumbers: { autoNumber: "AMS" },
            extensions: ["AMSmath.js", "AMSsymbols.js"] }
    }
});
</script>


      
    </div>

    
      
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-124774114-2', 'auto');
	
	ga('send', 'pageview');
}
</script>

    
  </body>
</html>
